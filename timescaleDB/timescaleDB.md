# TimescaleDB Deployment Instructions

This doc shows how to deploy the timescaleDB extension on top of Postgres17 as OEDs Database docker container.
*The reason for deploying with Postgres 17 was to confirm the latest version of timescale was enabled. Tangentially refer to [postgres17.md](./postgres17.md) docs for notes on deployment and upgrade help*

## Pull & Deploy Docker container

> Recommended to start from a fresh OED install to not corrupt/conflict `postgres-data/`

1. pull the specific docker image using the version tag ```docker pull timescale/timescaledb:2.21.1-pg17```
2. From your fresh repo of OED edit `containers/database/Dockerfile` and update the docker tag definition
   `FROM postgres:15.3`->`FROM timescale/timescaledb:2.21.1-pg17`
3. Then follow the typical steps to start up OED. Uncommenting port forwarding in docker-compose `database` and `docker compose up --build`

### TimescaleDB findings

1. In order to take advantage of the timescaleDB we need to create or adapt a table to use the hypertable function. Setting chunk size is how the table indexes time and still considering `tsdb.segmentby = 'meter'`. [Hypertable Doc](https://docs.tigerdata.com/use-timescale/latest/hypertables/) [Create HyperTable Doc](https://docs.tigerdata.com/api/latest/hypertable/create_hypertable/#arguments) [Optomization Docs](https://docs.tigerdata.com/use-timescale/latest/hypertables/improve-query-performance/#optimize-hypertable-chunk-intervals/)

    ``` sql
    #Create a copy of the readings table that we can meddle with and create a new colomn for hypertable to support(requires TIMESTAMPTZ)
    CREATE TABLE h_reading AS 
    TABLE readings;
    ALTER TABLE h_reading
    ADD COLUMN time TIMESTAMPTZ;
    
    UPDATE h_reading SET time = start_time AT TIME ZONE 'PDT';
    SELECT create_hypertable('h_reading', 'time')
    WITH (
       tsdb.hypertable,
       tsdb.partition_column='time',
       tsdb.chunk_interval='1 hour'
    );
     ```

2. The thing I'm still toying with are the settings for continuous_aggregate policy. start and end offset is the window of time this policy will look to. Schedule interval defaults to hourly

    ```sql
    SELECT add_continuous_aggregate_policy(
        'h_reading',
        start_offset => INTERVAL 'your_start_offset',
        end_offset => INTERVAL 'your_end_offset',
        schedule_interval => INTERVAL 'your_schedule_interval'
    );
    ```

generate_series
: can't be used post hyper table but hopefully can still be used for

tsrange
: still supported, but don't utilize hypertable indexing. The alternate is time_bucket

continuous_aggregate
: The timescale cron that checks if new rows have entered its table and begins processing the missing rows

Next steps to test timescale

```txt
Steps for automating the view
1. add some more readings and making sure it refreshes quickly
2. getting timescale to work with Meter hourly view
3. quantity of views up (including raw)
4. indicies access for readings faster. 
5. Manual earliest and latest views(If theyâ€™re faster how much faster are these things)

Goals
Meter hourly view(Readings come from there)
Daily meter is made by aggregating hourly.
Group hourly is done by agg meter hourly.
35k readings per year (under a minute)
```
